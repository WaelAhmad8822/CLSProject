{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnXGLcTzpLg_",
        "outputId": "3cce56c4-157a-44ce-bece-d1b6e4740335"
      },
      "outputs": [],
      "source": [
        "#!pip install xgboost lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3e94XtOlPoz3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E6qVkHHpLxx",
        "outputId": "50d405de-6bcf-4b9c-f30f-eb88a95e1e5d"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HwZiu2U-pL7z"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "features = pd.read_csv('features.csv')\n",
        "stores = pd.read_csv('stores.csv')\n",
        "customers_train = pd.read_csv('customer_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yamJMy5OYsIV"
      },
      "outputs": [],
      "source": [
        "train['Date'] = pd.to_datetime(train['Date'])\n",
        "features['Date'] = pd.to_datetime(features['Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ap6MI7bdY-Y8"
      },
      "outputs": [],
      "source": [
        "train_merged = train.merge(features, on=['Store','Date','IsHoliday'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nk9bgJaEZCZn"
      },
      "outputs": [],
      "source": [
        "train_merged = train_merged.merge(stores, on='Store', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GixwXaVJogyk",
        "outputId": "d93c98ba-868c-4a52-8120-c7fc0f23de4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”¹ Ø·ÙˆÙ„ train_merged: 421570\n",
            "ðŸ”¹ Ø·ÙˆÙ„ customer_train: 421570\n"
          ]
        }
      ],
      "source": [
        "print(f\"ðŸ”¹ Ø·ÙˆÙ„ train_merged: {len(train_merged)}\")\n",
        "print(f\"ðŸ”¹ Ø·ÙˆÙ„ customer_train: {len(customers_train)}\")\n",
        "min_len = min(len(train_merged), len(customers_train))\n",
        "\n",
        "train_trimmed = train_merged.iloc[:min_len].reset_index(drop=True)\n",
        "customers_trimmed = customers_train.iloc[:min_len].reset_index(drop=True)\n",
        "\n",
        "train_full = pd.concat([train_trimmed, customers_trimmed], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oUZUrujDosvu"
      },
      "outputs": [],
      "source": [
        "# train_full['Month'] = train_full['Date'].dt.strftime('%b %Y')\n",
        "# train_full['Date'].dt.strftime('%b')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wfL_bpkGgttC"
      },
      "outputs": [],
      "source": [
        "train_full['Fuel_Category'] = pd.cut(train_full['Fuel_Price'], bins=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB0UStY4XzDp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JqpJmJAfogym"
      },
      "outputs": [],
      "source": [
        "train_full['HasPromotion'] = train_full[['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']].sum(axis=1) > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uABft6XrefZ",
        "outputId": "91681139-2779-4791-81f7-f3ea632af17a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”¹ Weekly_Sales: 35521 outliers were clipped to within bounds\n",
            "ðŸ”¹ Temperature: 69 outliers were clipped to within bounds\n",
            "ðŸ”¹ MarkDown1: 55789 outliers were clipped to within bounds\n",
            "ðŸ”¹ MarkDown2: 103148 outliers were clipped to within bounds\n",
            "ðŸ”¹ MarkDown3: 84674 outliers were clipped to within bounds\n",
            "ðŸ”¹ MarkDown4: 79134 outliers were clipped to within bounds\n",
            "ðŸ”¹ MarkDown5: 40458 outliers were clipped to within bounds\n",
            "ðŸ”¹ Unemployment: 32114 outliers were clipped to within bounds\n",
            "ðŸ”¹ Num_Customers: 36494 outliers were clipped to within bounds\n",
            "ðŸ”¹ Avg_Spend_per_Customer: 69644 outliers were clipped to within bounds\n",
            "ðŸ”¹ Loyalty_Avg: 18225 outliers were clipped to within bounds\n",
            "ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© train_full\n"
          ]
        }
      ],
      "source": [
        "train_full = train_full.drop_duplicates()\n",
        "\n",
        "markdown_cols = ['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']\n",
        "train_full[markdown_cols] = train_full[markdown_cols].fillna(0)\n",
        "\n",
        "cols = [\n",
        "    'Weekly_Sales', 'Temperature', 'MarkDown1', 'MarkDown2', 'MarkDown3',\n",
        "    'MarkDown4', 'MarkDown5', 'Unemployment',\n",
        "    'Num_Customers', 'Avg_Spend_per_Customer', 'Loyalty_Avg'\n",
        "]\n",
        "\n",
        "\n",
        "for col in cols:\n",
        "    q1 = train_full[col].quantile(0.25)\n",
        "    q3 = train_full[col].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    upper = q3 + 1.5 * iqr\n",
        "    lower = q1 - 1.5 * iqr\n",
        "\n",
        "    before_outliers = ((train_full[col] < lower) | (train_full[col] > upper)).sum()\n",
        "    train_full[col] = train_full[col].clip(lower, upper)\n",
        "    after_outliers = ((train_full[col] < lower) | (train_full[col] > upper)).sum()\n",
        "\n",
        "    print(f\"ðŸ”¹ {col}: {before_outliers} outliers were clipped to within bounds\")\n",
        "\n",
        "print(\"ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© train_full\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JUMkndkL-OdT"
      },
      "outputs": [],
      "source": [
        "train_full['Year'] = train_full['Date'].dt.year\n",
        "train_full['Month'] = train_full['Date'].dt.month\n",
        "train_full['Week'] = train_full['Date'].dt.isocalendar().week\n",
        "train_full['Day'] = train_full['Date'].dt.day\n",
        "train_full['DayOfWeek'] = train_full['Date'].dt.dayofweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4DQ28Yofkvjn"
      },
      "outputs": [],
      "source": [
        "train_full = train_full.sort_values(['Store', 'Dept', 'Date'])\n",
        "\n",
        "train_full['Sales_Lag_4Weeks'] = train_full.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m-LER1_5CMBt"
      },
      "outputs": [],
      "source": [
        "train_full['IsHoliday'] = train_full['IsHoliday'].astype(int)\n",
        "train_full['HasPromotion'] = train_full['HasPromotion'].astype(int)\n",
        "train_full['Sales_Lag_4Weeks'] = train_full['Sales_Lag_4Weeks'].fillna(0).astype(int)\n",
        "\n",
        "\n",
        "train_full.drop('Date', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BjD6CruOogym"
      },
      "outputs": [],
      "source": [
        "data = pd.get_dummies(train_full, columns=['Type', 'Fuel_Category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "M-eDf3dbogyn",
        "outputId": "9167e6a2-2074-41b1-90c2-5b60e6d314d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>...</th>\n",
              "      <th>Fuel_Category_(2.47, 2.672]</th>\n",
              "      <th>Fuel_Category_(2.672, 2.871]</th>\n",
              "      <th>Fuel_Category_(2.871, 3.071]</th>\n",
              "      <th>Fuel_Category_(3.071, 3.27]</th>\n",
              "      <th>Fuel_Category_(3.27, 3.47]</th>\n",
              "      <th>Fuel_Category_(3.47, 3.67]</th>\n",
              "      <th>Fuel_Category_(3.67, 3.869]</th>\n",
              "      <th>Fuel_Category_(3.869, 4.069]</th>\n",
              "      <th>Fuel_Category_(4.069, 4.268]</th>\n",
              "      <th>Fuel_Category_(4.268, 4.468]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>0</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>1</td>\n",
              "      <td>38.51</td>\n",
              "      <td>2.548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>0</td>\n",
              "      <td>39.93</td>\n",
              "      <td>2.514</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19403.54</td>\n",
              "      <td>0</td>\n",
              "      <td>46.63</td>\n",
              "      <td>2.561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>21827.90</td>\n",
              "      <td>0</td>\n",
              "      <td>46.50</td>\n",
              "      <td>2.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store  Dept  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  MarkDown1  \\\n",
              "0      1     1      24924.50          0        42.31       2.572        0.0   \n",
              "1      1     1      46039.49          1        38.51       2.548        0.0   \n",
              "2      1     1      41595.55          0        39.93       2.514        0.0   \n",
              "3      1     1      19403.54          0        46.63       2.561        0.0   \n",
              "4      1     1      21827.90          0        46.50       2.625        0.0   \n",
              "\n",
              "   MarkDown2  MarkDown3  MarkDown4  ...  Fuel_Category_(2.47, 2.672]  \\\n",
              "0        0.0        0.0        0.0  ...                         True   \n",
              "1        0.0        0.0        0.0  ...                         True   \n",
              "2        0.0        0.0        0.0  ...                         True   \n",
              "3        0.0        0.0        0.0  ...                         True   \n",
              "4        0.0        0.0        0.0  ...                         True   \n",
              "\n",
              "   Fuel_Category_(2.672, 2.871]  Fuel_Category_(2.871, 3.071]  \\\n",
              "0                         False                         False   \n",
              "1                         False                         False   \n",
              "2                         False                         False   \n",
              "3                         False                         False   \n",
              "4                         False                         False   \n",
              "\n",
              "   Fuel_Category_(3.071, 3.27]  Fuel_Category_(3.27, 3.47]  \\\n",
              "0                        False                       False   \n",
              "1                        False                       False   \n",
              "2                        False                       False   \n",
              "3                        False                       False   \n",
              "4                        False                       False   \n",
              "\n",
              "   Fuel_Category_(3.47, 3.67]  Fuel_Category_(3.67, 3.869]  \\\n",
              "0                       False                        False   \n",
              "1                       False                        False   \n",
              "2                       False                        False   \n",
              "3                       False                        False   \n",
              "4                       False                        False   \n",
              "\n",
              "   Fuel_Category_(3.869, 4.069]  Fuel_Category_(4.069, 4.268]  \\\n",
              "0                         False                         False   \n",
              "1                         False                         False   \n",
              "2                         False                         False   \n",
              "3                         False                         False   \n",
              "4                         False                         False   \n",
              "\n",
              "   Fuel_Category_(4.268, 4.468]  \n",
              "0                         False  \n",
              "1                         False  \n",
              "2                         False  \n",
              "3                         False  \n",
              "4                         False  \n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pCAi6vCcogyn"
      },
      "outputs": [],
      "source": [
        "data.columns = data.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
        "\n",
        "X = data.drop('Weekly_Sales', axis=1)\n",
        "y = data['Weekly_Sales']\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "split_index = int(len(X) * 0.8)\n",
        "X_train, X_test, y_train, y_test = (\n",
        "    X.iloc[:split_index],\n",
        "    X.iloc[split_index:],\n",
        "    y.iloc[:split_index],\n",
        "    y.iloc[split_index:]\n",
        ")\n",
        "\n",
        "# Scaling X data\n",
        "X_train_scale = scaler_X.fit_transform(X_train)\n",
        "X_test_scale = scaler_X.transform(X_test)\n",
        "\n",
        "# Scaling y data\n",
        "y_train_scale = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scale = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Transforming data to dataframe and series\n",
        "X_train_scaled = pd.DataFrame(X_train_scale, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled  = pd.DataFrame(X_test_scale,  columns=X_test.columns,  index=X_test.index)\n",
        "\n",
        "y_train_scaled = pd.Series(y_train_scale.flatten(), index=y_train.index, name='Weekly_Sales')\n",
        "y_test_scaled = pd.Series(y_test_scale.flatten(), index=y_test.index, name='Weekly_Sales')\n",
        "\n",
        "# Sampling the train data\n",
        "sample_idx = y_train_scaled.sample(frac=0.1, random_state=42).index\n",
        "\n",
        "df_xsample_train = X_train_scaled.loc[sample_idx]\n",
        "df_ysample_train = y_train_scaled.loc[sample_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hUTGpBb5ogyn"
      },
      "outputs": [],
      "source": [
        "xgb_model = XGBRegressor(objective='reg:squarederror', eval_metric='rmse')\n",
        "xgb_params = {\n",
        "    'n_estimators': [200, 500, 800],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.5, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "\n",
        "lgb_model = LGBMRegressor()\n",
        "lgb_params = {\n",
        "    'n_estimators': [200, 500, 800],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'num_leaves': [15, 31, 63],\n",
        "    'max_depth': [-1, 5, 10],\n",
        "    'subsample': [0.7, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.7, 1.0]\n",
        "}\n",
        "\n",
        "\n",
        "rf_model = RandomForestRegressor()\n",
        "rf_params = {\n",
        "    'n_estimators': [200, 500, 800],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "gbr_model = GradientBoostingRegressor()\n",
        "gbr_params = {\n",
        "    'n_estimators': [200, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [2, 3, 5]\n",
        "}\n",
        "\n",
        "\n",
        "models = [xgb_model, rf_model, gbr_model, lgb_model]\n",
        "parameters = [xgb_params, rf_params, gbr_params, lgb_params]\n",
        "model_names = ['xgb', 'rf', 'gbr', 'lgb']\n",
        "\n",
        "all_models = []\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    return np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred))) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h74YzRIdogyn",
        "outputId": "75cd5060-6a5e-4ad7-864a-99c1957b19bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 0.013568237294053929\n",
            "RMSE: 0.022174688679380602\n",
            "R2: 0.9933903427050329\n",
            "MAPE: 0.0512857725415072\n",
            "SMAPE: 5.232461968535178\n",
            "Approx Accuracy: 94.76753803146482 %\n"
          ]
        }
      ],
      "source": [
        "linear_model=LinearRegression()\n",
        "linear_model.fit(df_xsample_train, df_ysample_train)\n",
        "preds=linear_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "mae = mean_absolute_error(y_test_scaled.values, preds)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_scaled.values, preds))\n",
        "r2 = r2_score(y_test_scaled.values, preds)\n",
        "mape = mean_absolute_percentage_error(y_test_scaled.values, preds)\n",
        "smape_val = smape(y_test_scaled.values, preds)\n",
        "accuracy = 100 - smape_val\n",
        "print(\"MAE:\", mae)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)\n",
        "print(\"MAPE:\", mape)\n",
        "print(\"SMAPE:\", smape_val)\n",
        "print(\"Approx Accuracy:\", accuracy, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WqBNgQ7Jogyn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 19\u001b[0m\n\u001b[0;32m      7\u001b[0m tscv \u001b[38;5;241m=\u001b[39m TimeSeriesSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      8\u001b[0m random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m      9\u001b[0m   estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     10\u001b[0m   param_distributions\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m   random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_xsample_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_ysample_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m best_model \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     21\u001b[0m best_params \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mbest_params_\n",
            "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Collect best models, params and metrics then save them to disk\n",
        "results = []\n",
        "import os, joblib, json\n",
        "os.makedirs('best_models', exist_ok=True)\n",
        "\n",
        "for model, params, name in zip(models, parameters, model_names):\n",
        "  tscv = TimeSeriesSplit(n_splits=5)\n",
        "  random = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=params,\n",
        "    cv=tscv,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_iter=10,\n",
        "    n_jobs=4,\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        "  )\n",
        "\n",
        "  random.fit(df_xsample_train, df_ysample_train)\n",
        "  best_model = random.best_estimator_\n",
        "  best_params = random.best_params_\n",
        "  all_models.append(best_model)\n",
        "\n",
        "  # persist the fitted estimator\n",
        "  model_path = os.path.join('best_models', f'{name}_best_model.joblib')\n",
        "  joblib.dump(best_model, model_path)\n",
        "\n",
        "  # predictions and metrics\n",
        "  preds = best_model.predict(X_test_scaled)\n",
        "  mae = mean_absolute_error(y_test_scaled.values, preds)\n",
        "  rmse = np.sqrt(mean_squared_error(y_test_scaled.values, preds))\n",
        "  r2 = r2_score(y_test_scaled.values, preds)\n",
        "  mape = mean_absolute_percentage_error(y_test_scaled.values, preds)\n",
        "  smape_val = smape(y_test_scaled.values, preds)\n",
        "  accuracy = 100 - smape_val\n",
        "\n",
        "  print('For', name + ':')\n",
        "  print(\"MAE:\", mae)\n",
        "  print(\"RMSE:\", rmse)\n",
        "  print(\"R2:\", r2)\n",
        "  print(\"MAPE:\", mape)\n",
        "  print(\"SMAPE:\", smape_val)\n",
        "  print(\"Approx Accuracy:\", accuracy, \"%\")\n",
        "  print()\n",
        "  print(best_params)\n",
        "  print()\n",
        "\n",
        "  # Append results (convert numerical metrics to native Python types)\n",
        "  results.append({\n",
        "    'model_name': name,\n",
        "    'model_path': model_path,\n",
        "    'best_params': best_params,\n",
        "    'mae': float(mae),\n",
        "    'rmse': float(rmse),\n",
        "    'r2': float(r2),\n",
        "    'mape': float(mape),\n",
        "    'smape': float(smape_val),\n",
        "    'accuracy': float(accuracy)\n",
        "  })\n",
        "\n",
        "# Save summary to disk (JSON) - params may contain numpy types, so use default=str\n",
        "with open(os.path.join('best_models','best_params_summary.json'),'w') as f:\n",
        "  json.dump(results, f, default=str, indent=2)\n",
        "\n",
        "import pandas as pd\n",
        "metrics_df = pd.DataFrame(results)\n",
        "print('\\nSummary of models:')\n",
        "print(metrics_df[[ 'model_name','mae','rmse','r2','mape','smape','accuracy']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reltdXZaUqVi"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "X8kvYNQDZ6Lw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VduQarcheXgH",
        "outputId": "374cace3-19b3-4512-9fd3-9e368d17b305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 421570 entries, 0 to 421569\n",
            "Data columns (total 26 columns):\n",
            " #   Column                  Non-Null Count   Dtype   \n",
            "---  ------                  --------------   -----   \n",
            " 0   Store                   421570 non-null  int64   \n",
            " 1   Dept                    421570 non-null  int64   \n",
            " 2   Weekly_Sales            421570 non-null  float64 \n",
            " 3   IsHoliday               421570 non-null  int32   \n",
            " 4   Temperature             421570 non-null  float64 \n",
            " 5   Fuel_Price              421570 non-null  float64 \n",
            " 6   MarkDown1               421570 non-null  float64 \n",
            " 7   MarkDown2               421570 non-null  float64 \n",
            " 8   MarkDown3               421570 non-null  float64 \n",
            " 9   MarkDown4               421570 non-null  float64 \n",
            " 10  MarkDown5               421570 non-null  float64 \n",
            " 11  CPI                     421570 non-null  float64 \n",
            " 12  Unemployment            421570 non-null  float64 \n",
            " 13  Type                    421570 non-null  object  \n",
            " 14  Size                    421570 non-null  int64   \n",
            " 15  Num_Customers           421570 non-null  float64 \n",
            " 16  Avg_Spend_per_Customer  421570 non-null  float64 \n",
            " 17  Loyalty_Avg             421570 non-null  float64 \n",
            " 18  Fuel_Category           421570 non-null  category\n",
            " 19  HasPromotion            421570 non-null  int32   \n",
            " 20  Year                    421570 non-null  int32   \n",
            " 21  Month                   421570 non-null  int32   \n",
            " 22  Week                    421570 non-null  UInt32  \n",
            " 23  Day                     421570 non-null  int32   \n",
            " 24  DayOfWeek               421570 non-null  int32   \n",
            " 25  Sales_Lag_4Weeks        421570 non-null  int32   \n",
            "dtypes: UInt32(1), category(1), float64(13), int32(7), int64(3), object(1)\n",
            "memory usage: 68.3+ MB\n"
          ]
        }
      ],
      "source": [
        "train_full.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SSletRyXb8es"
      },
      "outputs": [],
      "source": [
        "X = train_full.drop(\"Weekly_Sales\", axis=1)\n",
        "y = train_full[\"Weekly_Sales\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6IiuAZUWcEZ",
        "outputId": "ffe87591-7d81-4155-d397-065bec13e499"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031567 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3158\n",
            "[LightGBM] [Info] Number of data points in the train set: 337256, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 13655.762306\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "R2: 0.9980190066239593\n",
            "Training Completed. Sample Predictions: [47445.77555913  3389.94742124 10378.04679751  3411.86011928\n",
            "  6209.5075337 ]\n"
          ]
        }
      ],
      "source": [
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(drop='first', handle_unknown='ignore'), cat_cols),\n",
        "         (\"num\", MinMaxScaler(), num_cols)\n",
        "\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "lgbm_reg = LGBMRegressor(\n",
        "    subsample=0.9,\n",
        "    num_leaves=31,\n",
        "    n_estimators=500,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.05,\n",
        "    colsample_bytree=1.0\n",
        ")\n",
        "\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", lgbm_reg)\n",
        "])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test.values, y_pred)\n",
        "print(\"R2:\", r2)\n",
        "\n",
        "\n",
        "print(\"Training Completed. Sample Predictions:\", y_pred[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy0naPdg1jWd",
        "outputId": "cf2f241a-036a-4967-b0e6-cba09c9fbb33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving pipeline!....\n",
            "Pipeline saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Saving the model for deployment\n",
        "import joblib\n",
        "try:\n",
        "    print(\"Saving pipeline!....\")\n",
        "    pipeline_filename = 'gbr_pipeline.pkl'\n",
        "    joblib.dump(model, pipeline_filename);\n",
        "    print(\"Pipeline saved successfully!\")\n",
        "\n",
        "except Exception as err:\n",
        "    print(f\"Unexpected {err=}, {type(err)=}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
